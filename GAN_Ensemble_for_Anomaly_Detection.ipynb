{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-Ensemble-for-Anomaly-Detection.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMfKuO6oylkaptPCvHbW7Ro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demolakstate/anomaly_detection_sport_video/blob/main/GAN_Ensemble_for_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aM3cu55WtK8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuAjXTLzWwb_",
        "outputId": "f5ce6836-a0a6-4769-ea85-88c3b8524ca4"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Jh81elXUeL",
        "outputId": "fe2464f7-39f0-49bc-c729-4f6dcd35525b"
      },
      "source": [
        "cd /content/gdrive/MyDrive/Anomaly_Detection_in_Images/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Anomaly_Detection_in_Images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oOdexSR0-jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c5f8fa-d832-4e08-a503-5f6193b82a59"
      },
      "source": [
        "#!git clone https://github.com/tufts-ml/GAN-Ensemble-for-Anomaly-Detection.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GAN-Ensemble-for-Anomaly-Detection'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 58 (delta 8), reused 47 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E3l8kNQ1ZWp",
        "outputId": "7b0708ed-158d-498e-f6d4-6e90f6bb8966"
      },
      "source": [
        "cd GAN-Ensemble-for-Anomaly-Detection/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Anomaly_Detection_in_Images/GAN-Ensemble-for-Anomaly-Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yxpg1vezmXo",
        "outputId": "0931f63f-b4e2-41f7-a354-795adf9ed74e"
      },
      "source": [
        "ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdataloader\u001b[0m/   LICENSE      \u001b[01;34mmodels\u001b[0m/     README.md         train.py\n",
            "\u001b[01;34mexperiments\u001b[0m/  \u001b[01;34mLICENSE.md\u001b[0m/  options.py  requirements.txt  \u001b[01;34mutils\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JtPOzMgzmbq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goZKhmuiztZh"
      },
      "source": [
        "## Training ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2mJ61BJzmfa",
        "outputId": "29e0bd8c-9178-4bb4-b9ba-747859b737c7"
      },
      "source": [
        "!python train.py -h"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [--dataset DATASET] [--dataroot DATAROOT] [--path PATH]\n",
            "                [--setting SETTING] [--batchsize BATCHSIZE] [--split SPLIT]\n",
            "                [--workers WORKERS] [--droplast] [--isize ISIZE] [--nc NC]\n",
            "                [--nz NZ] [--ngf NGF] [--ndf NDF] [--extralayers EXTRALAYERS]\n",
            "                [--device DEVICE] [--ngpu NGPU] [--name NAME] [--model MODEL]\n",
            "                [--display_server DISPLAY_SERVER]\n",
            "                [--display_port DISPLAY_PORT] [--display_id DISPLAY_ID]\n",
            "                [--display] [--verbose] [--outf OUTF]\n",
            "                [--manualseed MANUALSEED] [--abnormal_class ABNORMAL_CLASS]\n",
            "                [--metric METRIC] [--bayes] [--n_G N_G] [--n_D N_D]\n",
            "                [--save_weight] [--arch ARCH] [--use_2disc] [--alpha ALPHA]\n",
            "                [--print_freq PRINT_FREQ] [--save_image_freq SAVE_IMAGE_FREQ]\n",
            "                [--save_test_images] [--load_weights] [--resume RESUME]\n",
            "                [--phase PHASE] [--iter ITER] [--niter NITER]\n",
            "                [--niter_decay NITER_DECAY] [--beta1 BETA1] [--lr LR]\n",
            "                [--sigma_lat SIGMA_LAT] [--scale_con SCALE_CON]\n",
            "                [--w_adv W_ADV] [--w_con W_CON] [--w_enc W_ENC]\n",
            "                [--lr_policy LR_POLICY] [--lr_decay_iters LR_DECAY_ITERS]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --dataset DATASET     folder | cifar10 | mnist | OCT | KDD99 (default:\n",
            "                        cifar10)\n",
            "  --dataroot DATAROOT   path to dataset (default: data)\n",
            "  --path PATH           path to the folder or image to be predicted. (default:\n",
            "                        )\n",
            "  --setting SETTING     skipgan | egbad| f-anogan|ganomaly, type of base\n",
            "                        models to ensemble (default: f-anogan)\n",
            "  --batchsize BATCHSIZE\n",
            "                        input batch size (default: 64)\n",
            "  --split SPLIT         number of forward pass before backprop (default: 1)\n",
            "  --workers WORKERS     number of data loading workers (default: 8)\n",
            "  --droplast            Drop last batch size. (default: True)\n",
            "  --isize ISIZE         input image size. (default: 32)\n",
            "  --nc NC               input image channels (default: 3)\n",
            "  --nz NZ               size of the latent z vector (default: 100)\n",
            "  --ngf NGF\n",
            "  --ndf NDF\n",
            "  --extralayers EXTRALAYERS\n",
            "                        Number of extra layers on gen and disc (default: 0)\n",
            "  --device DEVICE       Device: cuda | cpu (default: cuda)\n",
            "  --ngpu NGPU           number of GPUs to use (default: 1)\n",
            "  --name NAME           name of the experiment (default: speed)\n",
            "  --model MODEL         chooses which model to use. ganomaly. egbad (default:\n",
            "                        f-anogan)\n",
            "  --display_server DISPLAY_SERVER\n",
            "                        visdom server of the web display (default:\n",
            "                        http://localhost)\n",
            "  --display_port DISPLAY_PORT\n",
            "                        visdom port of the web display (default: 8097)\n",
            "  --display_id DISPLAY_ID\n",
            "                        window id of the web display (default: 0)\n",
            "  --display             Use visdom. (default: False)\n",
            "  --verbose             Print the training and model details. (default: False)\n",
            "  --outf OUTF           folder to output images and model checkpoints\n",
            "                        (default: ./output)\n",
            "  --manualseed MANUALSEED\n",
            "                        manual seed (default: -1)\n",
            "  --abnormal_class ABNORMAL_CLASS\n",
            "                        Anomaly class idx for mnist and cifar datasets\n",
            "                        (default: 0)\n",
            "  --metric METRIC       Evaluation metric: roc | auprc (default: roc)\n",
            "  --bayes               Drop last batch size. (default: False)\n",
            "  --n_G N_G             number of Generator parameters (default: 3)\n",
            "  --n_D N_D             number of Discriminator parameters (default: 3)\n",
            "  --save_weight         Save weight in each iteration (default: True)\n",
            "  --arch ARCH           DCGAN | UNET (default: UNET)\n",
            "  --use_2disc           Use two discriminator (default: False)\n",
            "  --alpha ALPHA         reconstruction rate for anomaly score (default: 0.9)\n",
            "  --print_freq PRINT_FREQ\n",
            "                        frequency of showing training results on console\n",
            "                        (default: 100)\n",
            "  --save_image_freq SAVE_IMAGE_FREQ\n",
            "                        frequency of saving real and fake images (default:\n",
            "                        100)\n",
            "  --save_test_images    Save test images for demo. (default: False)\n",
            "  --load_weights        Load the pretrained weights (default: False)\n",
            "  --resume RESUME       path to checkpoints (to continue training) (default: )\n",
            "  --phase PHASE         train, val, test, etc (default: train)\n",
            "  --iter ITER           Start from iteration i (default: 0)\n",
            "  --niter NITER         number of epochs to train for (default: 25)\n",
            "  --niter_decay NITER_DECAY\n",
            "                        # of iter to linearly decay learning rate to zero\n",
            "                        (default: 100)\n",
            "  --beta1 BETA1         momentum term of adam (default: 0.5)\n",
            "  --lr LR               initial learning rate for adam--0.0002 (default:\n",
            "                        0.0002)\n",
            "  --sigma_lat SIGMA_LAT\n",
            "                        Weight for latent space loss. default=1 (default: 1)\n",
            "  --scale_con SCALE_CON\n",
            "                        Weight for reconstruction loss. default=0.02 (default:\n",
            "                        0.02)\n",
            "  --w_adv W_ADV         Weight for adversarial loss. default=1 (default: 1)\n",
            "  --w_con W_CON         Reconstruction loss weight (default: 50)\n",
            "  --w_enc W_ENC         Encoder loss weight. (default: 1)\n",
            "  --lr_policy LR_POLICY\n",
            "                        lambda|step|plateau (default: lambda)\n",
            "  --lr_decay_iters LR_DECAY_ITERS\n",
            "                        multiply by a gamma every lr_decay_iters iterations\n",
            "                        (default: 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8QYo8Sm0vWF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQbbDPeH0wB5"
      },
      "source": [
        "## Install necessary libraries ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LqCX0NJ20vaU",
        "outputId": "a1c202cf-b270-4509-b489-57493f765212"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting certifi==2020.6.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 14.1MB/s \n",
            "\u001b[?25hCollecting Pillow==7.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/50/8e78e6f62ffa50d6ca95c281d5a2819bef66d023ac1b723e253de5bda9c5/Pillow-7.1.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image==0.16.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.16.2)\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 58.1MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 68.5MB/s \n",
            "\u001b[?25hCollecting tqdm==4.32.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/af/685bf3ce889ea191f3b916557f5677cc95a5e87b2fa120d74b5dd6d049d0/tqdm-4.32.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 59.1MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/9a/7eb9952f4b4d73fbd75ad1d5d6112f407e695957444cb695cbb3cdab918a/pandas-0.25.0-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5MB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.16.2->-r requirements.txt (line 3)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.16.2->-r requirements.txt (line 3)) (2.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.16.2->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.16.2->-r requirements.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->-r requirements.txt (line 4)) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.0->-r requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.0->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image==0.16.2->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->-r requirements.txt (line 3)) (2.4.7)\n",
            "\u001b[31mERROR: umap-learn 0.5.0 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.21.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.32.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.32.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: certifi, Pillow, scipy, scikit-learn, tqdm, torch, torchvision, pandas\n",
            "  Found existing installation: certifi 2020.12.5\n",
            "    Uninstalling certifi-2020.12.5:\n",
            "      Successfully uninstalled certifi-2020.12.5\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "Successfully installed Pillow-7.1.2 certifi-2020.6.20 pandas-0.25.0 scikit-learn-0.21.2 scipy-1.3.0 torch-1.4.0 torchvision-0.5.0 tqdm-4.32.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ham-thx607Ap"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXV9hKGbzmja",
        "outputId": "a14e7ca3-27a0-4b71-d646-b675cc952832"
      },
      "source": [
        "!python train.py \\\n",
        "         --dataset cifar10 \\\n",
        "         --niter 50 \\\n",
        "         --abnormal_class 9 \\\n",
        "         --setting ganomaly \\\n",
        "         --n_G 3 \\\n",
        "         --n_D 3 "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            ">> Training model Ganomaly.\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 1/50\n",
            "   Avg Run Time (ms/batch): 12.634 AUC: 0.613 max AUC: 0.613\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 2/50\n",
            "   Avg Run Time (ms/batch): 12.940 AUC: 0.576 max AUC: 0.613\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 3/50\n",
            "   Avg Run Time (ms/batch): 13.314 AUC: 0.614 max AUC: 0.614\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 4/50\n",
            "   Avg Run Time (ms/batch): 13.211 AUC: 0.560 max AUC: 0.614\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 5/50\n",
            "   Avg Run Time (ms/batch): 13.072 AUC: 0.603 max AUC: 0.614\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 6/50\n",
            "   Avg Run Time (ms/batch): 12.986 AUC: 0.555 max AUC: 0.614\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 7/50\n",
            "   Avg Run Time (ms/batch): 13.308 AUC: 0.689 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 8/50\n",
            "   Avg Run Time (ms/batch): 12.760 AUC: 0.593 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 9/50\n",
            "   Avg Run Time (ms/batch): 13.186 AUC: 0.642 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 10/50\n",
            "   Avg Run Time (ms/batch): 13.444 AUC: 0.524 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 11/50\n",
            "   Avg Run Time (ms/batch): 13.264 AUC: 0.625 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 12/50\n",
            "   Avg Run Time (ms/batch): 13.231 AUC: 0.657 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 13/50\n",
            "   Avg Run Time (ms/batch): 13.186 AUC: 0.644 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 14/50\n",
            "   Avg Run Time (ms/batch): 13.182 AUC: 0.626 max AUC: 0.689\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 15/50\n",
            "   Avg Run Time (ms/batch): 12.948 AUC: 0.690 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 16/50\n",
            "   Avg Run Time (ms/batch): 13.156 AUC: 0.630 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 17/50\n",
            "   Avg Run Time (ms/batch): 13.604 AUC: 0.611 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 18/50\n",
            "   Avg Run Time (ms/batch): 13.564 AUC: 0.601 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 19/50\n",
            "   Avg Run Time (ms/batch): 13.506 AUC: 0.616 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 20/50\n",
            "   Avg Run Time (ms/batch): 13.088 AUC: 0.648 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 21/50\n",
            "   Avg Run Time (ms/batch): 13.300 AUC: 0.610 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 22/50\n",
            "   Avg Run Time (ms/batch): 13.382 AUC: 0.623 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 23/50\n",
            "   Avg Run Time (ms/batch): 13.306 AUC: 0.657 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 24/50\n",
            "   Avg Run Time (ms/batch): 13.459 AUC: 0.656 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 25/50\n",
            "   Avg Run Time (ms/batch): 13.599 AUC: 0.630 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 26/50\n",
            "   Avg Run Time (ms/batch): 13.435 AUC: 0.653 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 27/50\n",
            "   Avg Run Time (ms/batch): 13.112 AUC: 0.583 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 28/50\n",
            "   Avg Run Time (ms/batch): 13.017 AUC: 0.660 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 29/50\n",
            "   Avg Run Time (ms/batch): 13.315 AUC: 0.656 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 30/50\n",
            "   Avg Run Time (ms/batch): 13.567 AUC: 0.631 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 31/50\n",
            "   Avg Run Time (ms/batch): 13.709 AUC: 0.616 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 32/50\n",
            "   Avg Run Time (ms/batch): 13.784 AUC: 0.641 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 33/50\n",
            "   Avg Run Time (ms/batch): 13.108 AUC: 0.626 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 34/50\n",
            "   Avg Run Time (ms/batch): 13.237 AUC: 0.662 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 35/50\n",
            "   Avg Run Time (ms/batch): 13.278 AUC: 0.654 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 36/50\n",
            "   Avg Run Time (ms/batch): 13.471 AUC: 0.657 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 37/50\n",
            "   Avg Run Time (ms/batch): 13.545 AUC: 0.630 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 38/50\n",
            "   Avg Run Time (ms/batch): 13.356 AUC: 0.652 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 39/50\n",
            "   Avg Run Time (ms/batch): 13.284 AUC: 0.657 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 40/50\n",
            "   Avg Run Time (ms/batch): 13.463 AUC: 0.629 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 41/50\n",
            "   Avg Run Time (ms/batch): 13.527 AUC: 0.630 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 42/50\n",
            "   Avg Run Time (ms/batch): 13.424 AUC: 0.652 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 43/50\n",
            "   Avg Run Time (ms/batch): 13.066 AUC: 0.654 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 44/50\n",
            "   Avg Run Time (ms/batch): 13.385 AUC: 0.653 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 45/50\n",
            "   Avg Run Time (ms/batch): 13.321 AUC: 0.625 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 46/50\n",
            "   Avg Run Time (ms/batch): 13.283 AUC: 0.667 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 47/50\n",
            "   Avg Run Time (ms/batch): 13.340 AUC: 0.625 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 48/50\n",
            "   Avg Run Time (ms/batch): 12.797 AUC: 0.634 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 49/50\n",
            "   Avg Run Time (ms/batch): 13.580 AUC: 0.650 max AUC: 0.690\n",
            "train <torch.utils.data.dataloader.DataLoader object at 0x7f0abbd977f0>\n",
            "++++++++++\n",
            ">> Training model Ganomaly. Epoch 50/50\n",
            "   Avg Run Time (ms/batch): 13.120 AUC: 0.662 max AUC: 0.690\n",
            ">> Training model Ganomaly.[Done]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6G0gozzzmnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJS8SKbuUzAQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ya7lyYbUz2D"
      },
      "source": [
        "## Load Custom dataset - exercise ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A2VsTBEUzJJ"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "                                     transforms.RandomSizedCrop(224),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                          std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tackle_dataset = datasets.ImageFolder(root='tackle_data/train',\n",
        "                                      transforms=data_transform)\n",
        "dataset_loader = torch.utils.data.DataLoader(tackle_dataset,\n",
        "                                             batch_size=4, shuffle=True,\n",
        "                                             num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvDrvzh7U6Hm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN9tcYsxU6Me"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t0UcsZ-zmqy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1_oxOTmzmua"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}