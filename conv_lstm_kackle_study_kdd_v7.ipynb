{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_lstm_kackle_study_kdd_v7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPgu65Z5X41JuY3bOJTLB2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demolakstate/anomaly_detection_sport_video/blob/main/conv_lstm_kackle_study_kdd_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s1f2_Qgo4m9r"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  \n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"conv_lstm_kackle_study_v2\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1vw2RPDDU-02Hst2Ef4N0s_zkqGdBX98q\n",
        "# Next-Frame Video Prediction with Convolutional LSTMs\n",
        "**Author:** [Amogh Joshi](https://github.com/amogh7joshi)<br>\n",
        "**Date created:** 2021/06/02<br>\n",
        "**Last modified:** 2021/06/05<br>\n",
        "**Description:** How to build and train a convolutional LSTM model for next-frame video prediction.\n",
        "## Introduction\n",
        "The\n",
        "[Convolutional LSTM](https://papers.nips.cc/paper/2015/file/07563a3fe3bbe7e3ba84431ad9d055af-Paper.pdf)\n",
        "architectures bring together time series processing and computer vision by\n",
        "introducing a convolutional recurrent cell in a LSTM layer. In this example, we will explore the\n",
        "Convolutional LSTM model in an application to next-frame prediction, the process\n",
        "of predicting what video frames come next given a series of past frames.\n",
        "## Setup\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import io\n",
        "import imageio\n",
        "from IPython.display import Image, display\n",
        "from ipywidgets import widgets, Layout, HBox\n",
        "import cv2\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iAwIMOn64oE_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"##Define hyperparameters\"\"\"\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 768#3072#768#1024\n",
        "IMG_SIZE = 128\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"## Dataset Construction\n",
        "For this example, we will be using the\n",
        "[Moving MNIST](http://www.cs.toronto.edu/~nitish/unsupervised_video/)\n",
        "dataset.\n",
        "We will download the dataset and then construct and\n",
        "preprocess training and validation sets.\n",
        "For next-frame prediction, our model will be using a previous frame,\n",
        "which we'll call `f_n`, to predict a new frame, called `f_(n + 1)`.\n",
        "To allow the model to create these predictions, we'll need to process\n",
        "the data such that we have \"shifted\" inputs and outputs, where the\n",
        "input data is frame `x_n`, being used to predict frame `y_(n + 1)`.\n",
        "##Data collection\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "VKy2z0ZH4oJZ",
        "outputId": "376f1d3a-856b-474f-eb65-e55653fa058f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'## Dataset Construction\\nFor this example, we will be using the\\n[Moving MNIST](http://www.cs.toronto.edu/~nitish/unsupervised_video/)\\ndataset.\\nWe will download the dataset and then construct and\\npreprocess training and validation sets.\\nFor next-frame prediction, our model will be using a previous frame,\\nwhich we\\'ll call `f_n`, to predict a new frame, called `f_(n + 1)`.\\nTo allow the model to create these predictions, we\\'ll need to process\\nthe data such that we have \"shifted\" inputs and outputs, where the\\ninput data is frame `x_n`, being used to predict frame `y_(n + 1)`.\\n##Data collection\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MliP1Zu4odn",
        "outputId": "b83ba8a8-484c-43ee-e2eb-4d16c6f1c0eb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Following method is modified from this tutorial:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "def load_video(path, max_frames=0):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            #frame = crop_center(frame)\n",
        "            # resize frames\n",
        "            frame = cv2.resize(frame, (128,128))\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            #print(f'frame shape: {frame.shape}')\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "#frames = load_video('/content/gdrive/MyDrive/ksutackle_dataset/risky_7.mp4', 20)\n",
        "\n",
        "#frames.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "tE6RVbfM41sD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let extract features\n",
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.DenseNet121(weights=\"imagenet\",include_top=False,pooling=\"avg\",\n",
        "                        input_shape=(IMG_SIZE, IMG_SIZE, 3), )\n",
        "    preprocess_input = keras.applications.densenet.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    # Add a dense layer\n",
        "    outputs = layers.Dense(768)(outputs)\n",
        "\n",
        "\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ],
      "metadata": {
        "id": "QEouphj76L2d"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for layer in feature_extractor.layers[:-1]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "9F9cjb-8fQdN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxJbdcwDTsbK",
        "outputId": "f08f24d4-96ba-40ad-fae6-2575f54a50ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"feature_extractor\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " tf.math.truediv_2 (TFOpLamb  (None, 128, 128, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.nn.bias_add_1 (TFOpLambd  (None, 128, 128, 3)      0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " tf.math.truediv_3 (TFOpLamb  (None, 128, 128, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 1024)              7037504   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 768)               787200    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,824,704\n",
            "Trainable params: 787,200\n",
            "Non-trainable params: 7,037,504\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_all_videos(root_dir, frames_all=[]):\n",
        "    \n",
        "    video_paths = os.listdir(root_dir)\n",
        "    labels = [video_path.split('_')[0] for video_path in video_paths]\n",
        "    num_samples = len(labels)\n",
        "    \n",
        "    # `frame_features` are what we will feed to our sequence model.\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "\n",
        "        # Call visualization here\n",
        "\n",
        "        # Pad shorter videos.\n",
        "        if len(frames) < MAX_SEQ_LENGTH:\n",
        "            diff = MAX_SEQ_LENGTH - len(frames)\n",
        "            padding = np.zeros((diff, IMG_SIZE, IMG_SIZE, 3))\n",
        "            frames = np.concatenate(frames, padding)\n",
        "\n",
        "        frames = frames[:20]\n",
        "        frames = frames[None, ...]\n",
        "         # Initialize placeholder to store the features of the current video.\n",
        "        temp_frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                if np.mean(batch[j, :]) > 0.0:\n",
        "                    temp_frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :] )\n",
        "                else:\n",
        "                    temp_frame_features[i, j, :] = 0.0\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "\n",
        "    print(frame_features.shape)\n",
        "\n",
        "    return frame_features\n",
        "\n",
        "        #frames_all.append(frames)\n",
        "\n",
        "    #return np.array(frames_all)\n"
      ],
      "metadata": {
        "id": "vgkwgo-m5dls"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cap = cv2.VideoCapture('/content/gdrive/MyDrive/ksutackle_dataset/risky_7.mp4')\n",
        "ret, frame = cap.read()\n",
        "i = 0\n",
        "\n",
        "while ret:\n",
        "  # try:\n",
        "  #   ret, frame = cap.read()\n",
        "  #   if not ret:\n",
        "  #     break\n",
        "    #cv2_imshow(frame)\n",
        "    #frame = crop_center(frame)\n",
        "    #cv2.imwrite(f'frame_{i}.jpg', frame)\n",
        "    ret, frame = cap.read()\n",
        "    i += 1\n",
        "    #cv2_imshow(frame)\n",
        "    #frame = frame[:,:,[1,2,0]]\n",
        "    #print(frame.shape)\n",
        "    #cv2_imshow(frame)\n",
        "\n",
        "\n",
        "  # finally:\n",
        "  #   cap.release()"
      ],
      "metadata": {
        "id": "TWGdExen5dps"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Kgxt2bl25dtu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axRgKahF4O8s",
        "outputId": "835999c0-cf0e-4e85-c74a-5f5e3bb9eb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from disk\n",
            "Frame features in train set: (75, 20, 768)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    data = np.load(\"data_conv_lstm.npy\")\n",
        "    print(\"Successfully loaded data from disk\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Dataset not available on disk, preparing a new one...\")\n",
        "    #data = prepare_all_videos('../../ksutackle_dataset_108')\n",
        "    data = prepare_all_videos('/content/gdrive/MyDrive/ksutackle_dataset')\n",
        "    np.save(\"data_conv_lstm.npy\", data)\n",
        "    #np.save(\"labels.npy\", labels)\n",
        "\n",
        "train_data_all, test_data  = train_test_split(data, test_size=0.30, random_state=42)\n",
        "#train_data, val_data, train_labels, val_labels = train_test_split(train_data_all, train_labels_all, test_size=0.20, random_state=45)\n",
        "print(f\"Frame features in train set: {train_data_all.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Normalize the data to the 0-1 range.\n",
        "train_dataset = train_data_all / 255\n",
        "val_dataset = test_data / 255\n",
        "\n",
        "# We'll define a helper function to shift the frames, where\n",
        "# `x` is frames 0 to n - 1, and `y` is frames 1 to n.\n",
        "def create_shifted_frames(data):\n",
        "    # x = data[:, 0 : data.shape[1] - 1, :, :]\n",
        "    # y = data[:, 1 : data.shape[1], :, :]\n",
        "    x = data[:, 0 : data.shape[1] - 1, :]\n",
        "    y = data[:, 1 : data.shape[1], :]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "# Apply the processing function to the datasets.\n",
        "x_train, y_train = create_shifted_frames(train_dataset)\n",
        "x_val, y_val = create_shifted_frames(val_dataset)\n",
        "\n",
        "# Inspect the dataset.\n",
        "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5ehxgPZItx4",
        "outputId": "39fa19d8-bd6d-44db-b7cd-75d980a38915"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Shapes: (75, 19, 768), (75, 19, 768)\n",
            "Validation Dataset Shapes: (33, 19, 768), (33, 19, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = layers.Reshape((-1,16,16,3))(x_train)\n",
        "y_train = layers.Reshape((-1,16,16,3))(y_train)\n",
        "\n",
        "x_val = layers.Reshape((-1,16,16,3))(x_val)\n",
        "y_val = layers.Reshape((-1,16,16,3))(y_val)"
      ],
      "metadata": {
        "id": "Fm76UhHXKOH6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VEFoXDe-KONi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"## Data Visualization\n",
        "Our data consists of sequences of frames, each of which\n",
        "are used to predict the upcoming frame. Let's take a look\n",
        "at some of these sequential frames.\n",
        "\"\"\"\n",
        "\n",
        "# Construct a figure on which we will visualize the images.\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 8))\n",
        "#axes -= 1\n",
        "\n",
        "# Plot each of the sequential images for one random data example.\n",
        "data_choice = np.random.choice(range(len(train_dataset)), size=1)[0]\n",
        "for idx, ax in enumerate(axes.flat):\n",
        "    #ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap=\"gray\")\n",
        "    ax.imshow(y_train[data_choice][idx], cmap=\"brg\")\n",
        "    ax.set_title(f\"Frame {idx + 1}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Print information and display the figure.\n",
        "print(f\"Displaying frames for example {data_choice}.\")\n",
        "plt.show()\n",
        "\n",
        "\"\"\"## Model Construction\n",
        "To build a Convolutional LSTM model, we will use the\n",
        "`ConvLSTM2D` layer, which will accept inputs of shape\n",
        "`(batch_size, num_frames, width, height, channels)`, and return\n",
        "a prediction movie of the same shape.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "cbaaYsZwIt1t",
        "outputId": "c7f5ae3e-387a-443f-d5c1-1cda6700e34d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying frames for example 62.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'## Model Construction\\nTo build a Convolutional LSTM model, we will use the\\n`ConvLSTM2D` layer, which will accept inputs of shape\\n`(batch_size, num_frames, width, height, channels)`, and return\\na prediction movie of the same shape.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SpxRdKnOJq6O"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip('horizontal'),tf.keras.layers.RandomRotation(0.2),])\n",
        "# preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "# # Create the base model from the pre-trained model MobileNet V2\n",
        "# IMG_SHAPE = IMG_SIZE + (3,)\n",
        "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "# #image_batch, label_batch = next(iter(train_dataset))\n",
        "# feature_batch = base_model(x_train[0])\n",
        "# print(feature_batch.shape)"
      ],
      "metadata": {
        "id": "8KkfRlIOIt5n"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OcjsHzd8It9I"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Construct the input layer with no definite frame size.\n",
        "inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "\n",
        "#x = layers.Reshape((-1,16,16,3))(inp)\n",
        "\n",
        "print(inp.shape)\n",
        "\n",
        "# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
        "# followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(5, 5),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\",\n",
        ")(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(3, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\",\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(1, 1),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\",\n",
        ")(x)\n",
        "x = layers.Conv3D(\n",
        "    filters=3, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "print(inp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuToSoel6cH0",
        "outputId": "6957375f-55e2-4ada-de81-371a78e743c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, None, 16, 16, 3)\n",
            "(None, None, 16, 16, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we will build the complete model and compile it.\n",
        "model = keras.models.Model(inp, x)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),\n",
        ")\n",
        "\n",
        "\"\"\"## Model Training\n",
        "With our model and data constructed, we can now train the model.\n",
        "\"\"\"\n",
        "\n",
        "# Define some callbacks to improve training.\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
        "\n",
        "# Define modifiable training hyperparameters.\n",
        "epochs = 20\n",
        "batch_size = 5\n",
        "\n",
        "# Fit the model to the training data.\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        ")\n",
        "\n",
        "\n",
        "model.save('model_conv_lstm_v2.h5')\n",
        "\"\"\"## Frame Prediction Visualizations\n",
        "With our model now constructed and trained, we can generate\n",
        "some example frame predictions based on a new video.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "D6HGoM0MLQp3",
        "outputId": "9980e9d7-9af7-468f-b4b7-a47c0f1606ad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 68s 4s/step - loss: -37180.0625 - val_loss: -55.9850 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 58s 4s/step - loss: -552.2786 - val_loss: -20.6555 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 58s 4s/step - loss: -91.3224 - val_loss: -22.0253 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 58s 4s/step - loss: -84.3361 - val_loss: -27.0355 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 58s 4s/step - loss: -66.6039 - val_loss: -29.0198 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 58s 4s/step - loss: -50.7041 - val_loss: -29.0928 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 58s 4s/step - loss: -46.9788 - val_loss: -26.6771 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 58s 4s/step - loss: -46.8092 - val_loss: -26.8609 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 59s 4s/step - loss: -47.0309 - val_loss: -27.2274 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 59s 4s/step - loss: -47.2431 - val_loss: -27.4087 - lr: 1.0000e-04\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 59s 4s/step - loss: -47.4518 - val_loss: -27.4059 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'## Frame Prediction Visualizations\\nWith our model now constructed and trained, we can generate\\nsome example frame predictions based on a new video.'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.plot(history.history['accuracy'], label='training_accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='validation_accuracy')\n",
        "# #plt.plot(history.history['loss'], label='training_loss')\n",
        "# #plt.plot(history.history['val_loss'], label='validation_loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# #plt.title('Accuracy')\n",
        "# plt.legend()\n",
        "# plt.imshow()\n",
        "# plt.savefig('plt_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "\n"
      ],
      "metadata": {
        "id": "-TxtDAB4h64M"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#plt.plot(history.history['accuracy'], label='training_accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='validation_accuracy')\n",
        "plt.plot(history.history['loss'], label='training_loss')\n",
        "plt.plot(history.history['val_loss'], label='validation_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "#plt.title('Accuracy')\n",
        "plt.legend()\n",
        "#plt.imshow()\n",
        "plt.savefig('plt_loss.png', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ug4OGG2ciW31",
        "outputId": "7d4c8f75-aaa9-4fc5-9b78-4ac679a94b60"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZWhPQjX66cMX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "laycUNzQ6cQX"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}