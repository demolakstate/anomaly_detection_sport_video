{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_lstm_kackle_study_kdd_v8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2AeuNRGxy5dQW+w32zvY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demolakstate/anomaly_detection_sport_video/blob/main/conv_lstm_kackle_study_kdd_v8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s1f2_Qgo4m9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  \n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"conv_lstm_kackle_study_v2\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1vw2RPDDU-02Hst2Ef4N0s_zkqGdBX98q\n",
        "# Next-Frame Video Prediction with Convolutional LSTMs\n",
        "**Author:** [Amogh Joshi](https://github.com/amogh7joshi)<br>\n",
        "**Date created:** 2021/06/02<br>\n",
        "**Last modified:** 2021/06/05<br>\n",
        "**Description:** How to build and train a convolutional LSTM model for next-frame video prediction.\n",
        "## Introduction\n",
        "The\n",
        "[Convolutional LSTM](https://papers.nips.cc/paper/2015/file/07563a3fe3bbe7e3ba84431ad9d055af-Paper.pdf)\n",
        "architectures bring together time series processing and computer vision by\n",
        "introducing a convolutional recurrent cell in a LSTM layer. In this example, we will explore the\n",
        "Convolutional LSTM model in an application to next-frame prediction, the process\n",
        "of predicting what video frames come next given a series of past frames.\n",
        "## Setup\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import io\n",
        "import imageio\n",
        "from IPython.display import Image, display\n",
        "from ipywidgets import widgets, Layout, HBox\n",
        "import cv2\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iAwIMOn64oE_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"##Define hyperparameters\"\"\"\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 768#3072#768#1024\n",
        "IMG_SIZE = 128\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"## Dataset Construction\n",
        "For this example, we will be using the\n",
        "[Moving MNIST](http://www.cs.toronto.edu/~nitish/unsupervised_video/)\n",
        "dataset.\n",
        "We will download the dataset and then construct and\n",
        "preprocess training and validation sets.\n",
        "For next-frame prediction, our model will be using a previous frame,\n",
        "which we'll call `f_n`, to predict a new frame, called `f_(n + 1)`.\n",
        "To allow the model to create these predictions, we'll need to process\n",
        "the data such that we have \"shifted\" inputs and outputs, where the\n",
        "input data is frame `x_n`, being used to predict frame `y_(n + 1)`.\n",
        "##Data collection\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "VKy2z0ZH4oJZ",
        "outputId": "3e686bd3-aa14-441f-aa20-c8e5ed35f498"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'## Dataset Construction\\nFor this example, we will be using the\\n[Moving MNIST](http://www.cs.toronto.edu/~nitish/unsupervised_video/)\\ndataset.\\nWe will download the dataset and then construct and\\npreprocess training and validation sets.\\nFor next-frame prediction, our model will be using a previous frame,\\nwhich we\\'ll call `f_n`, to predict a new frame, called `f_(n + 1)`.\\nTo allow the model to create these predictions, we\\'ll need to process\\nthe data such that we have \"shifted\" inputs and outputs, where the\\ninput data is frame `x_n`, being used to predict frame `y_(n + 1)`.\\n##Data collection\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MliP1Zu4odn",
        "outputId": "aac7942a-2e4a-4120-dad9-70c06e0c9870"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Following method is modified from this tutorial:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "def load_video(path, max_frames=0):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            #frame = crop_center(frame)\n",
        "            # resize frames\n",
        "            frame = cv2.resize(frame, (128,128))\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            #print(f'frame shape: {frame.shape}')\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "#frames = load_video('/content/gdrive/MyDrive/ksutackle_dataset/risky_7.mp4', 20)\n",
        "\n",
        "#frames.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "tE6RVbfM41sD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let extract features\n",
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.DenseNet121(weights=\"imagenet\",include_top=False,pooling=\"avg\",\n",
        "                        input_shape=(IMG_SIZE, IMG_SIZE, 3), )\n",
        "    preprocess_input = keras.applications.densenet.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    # Add a dense layer\n",
        "    outputs = layers.Dense(768)(outputs)\n",
        "\n",
        "\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ],
      "metadata": {
        "id": "QEouphj76L2d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for layer in feature_extractor.layers[:-1]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "9F9cjb-8fQdN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxJbdcwDTsbK",
        "outputId": "e13237d6-3969-4018-b7eb-d8222131feb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"feature_extractor\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 128, 128, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.nn.bias_add (TFOpLambda)  (None, 128, 128, 3)      0         \n",
            "                                                                 \n",
            " tf.math.truediv_1 (TFOpLamb  (None, 128, 128, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 1024)              7037504   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 768)               787200    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,824,704\n",
            "Trainable params: 787,200\n",
            "Non-trainable params: 7,037,504\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_all_videos(root_dir, frames_all=[]):\n",
        "    \n",
        "    video_paths = os.listdir(root_dir)\n",
        "    labels = [video_path.split('_')[0] for video_path in video_paths]\n",
        "    num_samples = len(labels)\n",
        "    \n",
        "    # `frame_features` are what we will feed to our sequence model.\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "\n",
        "        # Call visualization here\n",
        "\n",
        "        # Pad shorter videos.\n",
        "        if len(frames) < MAX_SEQ_LENGTH:\n",
        "            diff = MAX_SEQ_LENGTH - len(frames)\n",
        "            padding = np.zeros((diff, IMG_SIZE, IMG_SIZE, 3))\n",
        "            frames = np.concatenate(frames, padding)\n",
        "\n",
        "        frames = frames[:20]\n",
        "        frames = frames[None, ...]\n",
        "         # Initialize placeholder to store the features of the current video.\n",
        "        temp_frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                if np.mean(batch[j, :]) > 0.0:\n",
        "                    temp_frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :] )\n",
        "                else:\n",
        "                    temp_frame_features[i, j, :] = 0.0\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "\n",
        "    print(frame_features.shape)\n",
        "\n",
        "    return frame_features\n",
        "\n",
        "        #frames_all.append(frames)\n",
        "\n",
        "    #return np.array(frames_all)\n"
      ],
      "metadata": {
        "id": "vgkwgo-m5dls"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cap = cv2.VideoCapture('/content/gdrive/MyDrive/ksutackle_dataset/risky_7.mp4')\n",
        "ret, frame = cap.read()\n",
        "i = 0\n",
        "\n",
        "while ret:\n",
        "  # try:\n",
        "  #   ret, frame = cap.read()\n",
        "  #   if not ret:\n",
        "  #     break\n",
        "    #cv2_imshow(frame)\n",
        "    #frame = crop_center(frame)\n",
        "    #cv2.imwrite(f'frame_{i}.jpg', frame)\n",
        "    ret, frame = cap.read()\n",
        "    i += 1\n",
        "    #cv2_imshow(frame)\n",
        "    #frame = frame[:,:,[1,2,0]]\n",
        "    #print(frame.shape)\n",
        "    #cv2_imshow(frame)\n",
        "\n",
        "\n",
        "  # finally:\n",
        "  #   cap.release()"
      ],
      "metadata": {
        "id": "TWGdExen5dps"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Kgxt2bl25dtu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axRgKahF4O8s",
        "outputId": "69279f3c-f93e-43ad-dbe5-657c0b100f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from disk\n",
            "Frame features in train set: (75, 20, 768)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    data = np.load(\"data_conv_lstm.npy\")\n",
        "    print(\"Successfully loaded data from disk\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Dataset not available on disk, preparing a new one...\")\n",
        "    #data = prepare_all_videos('../../ksutackle_dataset_108')\n",
        "    data = prepare_all_videos('/content/gdrive/MyDrive/ksutackle_dataset')\n",
        "    np.save(\"data_conv_lstm.npy\", data)\n",
        "    #np.save(\"labels.npy\", labels)\n",
        "\n",
        "train_data_all, test_data  = train_test_split(data, test_size=0.30, random_state=42)\n",
        "#train_data, val_data, train_labels, val_labels = train_test_split(train_data_all, train_labels_all, test_size=0.20, random_state=45)\n",
        "print(f\"Frame features in train set: {train_data_all.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Normalize the data to the 0-1 range.\n",
        "train_dataset = train_data_all / 255\n",
        "val_dataset = test_data / 255\n",
        "\n",
        "# We'll define a helper function to shift the frames, where\n",
        "# `x` is frames 0 to n - 1, and `y` is frames 1 to n.\n",
        "def create_shifted_frames(data):\n",
        "    # x = data[:, 0 : data.shape[1] - 1, :, :]\n",
        "    # y = data[:, 1 : data.shape[1], :, :]\n",
        "    x = data[:, 0 : data.shape[1] - 1, :]\n",
        "    y = data[:, 1 : data.shape[1], :]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "# Apply the processing function to the datasets.\n",
        "x_train, y_train = create_shifted_frames(train_dataset)\n",
        "x_val, y_val = create_shifted_frames(val_dataset)\n",
        "\n",
        "# Inspect the dataset.\n",
        "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5ehxgPZItx4",
        "outputId": "639761d1-54da-48fb-84d3-2657ba9f8d85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Shapes: (75, 19, 768), (75, 19, 768)\n",
            "Validation Dataset Shapes: (33, 19, 768), (33, 19, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = layers.Reshape((-1,16,16,3))(x_train)\n",
        "y_train = layers.Reshape((-1,16,16,3))(y_train)\n",
        "\n",
        "x_val = layers.Reshape((-1,16,16,3))(x_val)\n",
        "y_val = layers.Reshape((-1,16,16,3))(y_val)"
      ],
      "metadata": {
        "id": "Fm76UhHXKOH6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VEFoXDe-KONi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"## Data Visualization\n",
        "Our data consists of sequences of frames, each of which\n",
        "are used to predict the upcoming frame. Let's take a look\n",
        "at some of these sequential frames.\n",
        "\"\"\"\n",
        "\n",
        "# Construct a figure on which we will visualize the images.\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 8))\n",
        "#axes -= 1\n",
        "\n",
        "# Plot each of the sequential images for one random data example.\n",
        "data_choice = np.random.choice(range(len(train_dataset)), size=1)[0]\n",
        "for idx, ax in enumerate(axes.flat):\n",
        "    #ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap=\"gray\")\n",
        "    ax.imshow(y_train[data_choice][idx], cmap=\"brg\")\n",
        "    ax.set_title(f\"Frame {idx + 1}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Print information and display the figure.\n",
        "print(f\"Displaying frames for example {data_choice}.\")\n",
        "plt.show()\n",
        "\n",
        "\"\"\"## Model Construction\n",
        "To build a Convolutional LSTM model, we will use the\n",
        "`ConvLSTM2D` layer, which will accept inputs of shape\n",
        "`(batch_size, num_frames, width, height, channels)`, and return\n",
        "a prediction movie of the same shape.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "cbaaYsZwIt1t",
        "outputId": "4b1f261a-9b5f-47f3-a7c9-4644e615443f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying frames for example 64.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'## Model Construction\\nTo build a Convolutional LSTM model, we will use the\\n`ConvLSTM2D` layer, which will accept inputs of shape\\n`(batch_size, num_frames, width, height, channels)`, and return\\na prediction movie of the same shape.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SpxRdKnOJq6O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip('horizontal'),tf.keras.layers.RandomRotation(0.2),])\n",
        "# preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "# # Create the base model from the pre-trained model MobileNet V2\n",
        "# IMG_SHAPE = IMG_SIZE + (3,)\n",
        "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "# #image_batch, label_batch = next(iter(train_dataset))\n",
        "# feature_batch = base_model(x_train[0])\n",
        "# print(feature_batch.shape)"
      ],
      "metadata": {
        "id": "8KkfRlIOIt5n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OcjsHzd8It9I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Construct the input layer with no definite frame size.\n",
        "inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "\n",
        "#x = layers.Reshape((-1,16,16,3))(inp)\n",
        "\n",
        "print(inp.shape)\n",
        "\n",
        "# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
        "# followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(5, 5),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\",\n",
        ")(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(3, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\",\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(1, 1),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\",\n",
        ")(x)\n",
        "x = layers.Conv3D(\n",
        "    filters=3, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "print(inp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuToSoel6cH0",
        "outputId": "26d1516a-93e1-4dad-9185-a04831765573"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, None, 16, 16, 3)\n",
            "(None, None, 16, 16, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we will build the complete model and compile it.\n",
        "model = keras.models.Model(inp, x)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),\n",
        ")\n",
        "\n",
        "\"\"\"## Model Training\n",
        "With our model and data constructed, we can now train the model.\n",
        "\"\"\"\n",
        "\n",
        "# Define some callbacks to improve training.\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
        "\n",
        "# Define modifiable training hyperparameters.\n",
        "epochs = 100\n",
        "batch_size = 5\n",
        "\n",
        "# Fit the model to the training data.\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        ")\n",
        "\n",
        "\n",
        "model.save('model_conv_lstm_v2.h5')\n",
        "\"\"\"## Frame Prediction Visualizations\n",
        "With our model now constructed and trained, we can generate\n",
        "some example frame predictions based on a new video.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6HGoM0MLQp3",
        "outputId": "3d1ee176-e4e7-46c3-e35d-e945fe6c8f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 66s 4s/step - loss: 0.1877 - val_loss: 0.4625 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 58s 4s/step - loss: -0.0258 - val_loss: 0.1279 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 56s 4s/step - loss: -0.3453 - val_loss: 0.0597 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: -5.4607 - val_loss: 0.0306 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: -826.7192 - val_loss: -1.4600 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: -277092.5938 - val_loss: -1683.9419 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: -22955746.0000 - val_loss: -57751.5781 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: -123054160.0000 - val_loss: -3156333.0000 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: -43542675456.0000 - val_loss: -570994112.0000 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 56s 4s/step - loss: -4770473967616.0000 - val_loss: -105976438784.0000 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: -550692351639552.0000 - val_loss: -32284652601344.0000 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 56s 4s/step - loss: -28658564419551232.0000 - val_loss: -5075652227104768.0000 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 56s 4s/step - loss: -868457574255558656.0000 - val_loss: -323060190100324352.0000 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: nan - val_loss: nan - lr: 0.0010\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: nan - val_loss: nan - lr: 0.0010\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 56s 4s/step - loss: nan - val_loss: nan - lr: 0.0010\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 56s 4s/step - loss: nan - val_loss: nan - lr: 0.0010\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 57s 4s/step - loss: nan - val_loss: nan - lr: 0.0010\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 56s 4s/step - loss: nan - val_loss: nan - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            " 4/15 [=======>......................] - ETA: 37s - loss: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.plot(history.history['accuracy'], label='training_accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='validation_accuracy')\n",
        "# #plt.plot(history.history['loss'], label='training_loss')\n",
        "# #plt.plot(history.history['val_loss'], label='validation_loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# #plt.title('Accuracy')\n",
        "# plt.legend()\n",
        "# plt.imshow()\n",
        "# plt.savefig('plt_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "\n"
      ],
      "metadata": {
        "id": "-TxtDAB4h64M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#plt.plot(history.history['accuracy'], label='training_accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='validation_accuracy')\n",
        "plt.plot(history.history['loss'], label='training_loss')\n",
        "plt.plot(history.history['val_loss'], label='validation_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "#plt.title('Accuracy')\n",
        "plt.legend()\n",
        "#plt.imshow()\n",
        "plt.savefig('plt_loss.png', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "Ug4OGG2ciW31",
        "outputId": "2663702e-dbf1-4137-cf6f-9c0c12a72672"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAERCAYAAABy/XBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3zU9Z3v8dcnF0gmhJAJd5IIWpGQhGtEXA6olXqo9wtUXfUI9fKo67runq17bPs4tfXB6fZhrbKetevBXd3qsfVC1XZ7qlWpLdrFKiIooFa5COGahDshgSSf88dMQoAEhmQmv5nM+/l4zIOZX2Z+v8+Py7z5fX/fi7k7IiKSfjKCLkBERIKhABARSVMKABGRNKUAEBFJUwoAEZE0pQAQEUlTKRcAZvaEme0ws1UxvHeGmS03syYzm91u+wVmtqLdo8HMrkxs5SIiycVSbRyAmc0A9gNPuXvFSd47EugPfBP4lbsv6uA9YeBzoNjd6+NesIhIkkq5KwB3XwLsbL/NzM4ws1fN7H0ze8vMxkTfu8HdPwRaTrDL2cAr+vIXkXSTcgHQiYXAXe4+mcj/9n9yCp+9Dvh5QqoSEUliWUEX0F1m1g/4C+AFM2vd3DfGzw4DKoHfJqY6EZHklfIBQOQqZre7T+jCZ78GvOTuh+Nck4hI0kv5JiB33wusN7M5ABYxPsaPX4+af0QkTaViL6CfA+cDA4HtwH3A74B/AYYB2cCz7n6/mZ0NvAQUAg3ANncvj+5nJPBHoMTdT3STWESkV0q5ABARkfhI+SYgERHpmpS6CTxw4EAfOXJk0GWIiKSU999/v9bdBx27PaUCYOTIkSxbtizoMkREUoqZfdHRdjUBiYikKQWAiEiaUgCIiKQpBYCISJpSAIiIpKlAA8DMZpnZp2b2uZndG2QtIiLpJrAAMLNM4FHgq8BY4HozGxtUPSIi6SbIcQBTgM/dfR2AmT0LXAGsifeBVix+lob178Z7tyLSXQaGtT6lbUb39tsN2iZ6t+jWtm3W9hlr97nWfRXk5zN00ECy+uZBn2Me2a3PQ9CnH2Rm98QZJ5UgA2AEsKnd62rgnGPfZGa3A7cDlJaWdulAjR//lik1L3XpsyKSHDIswfOWZfaB7GgY9AkdExLtgiI7+rPW9w2pgBGTEltbgiT9SGB3X0hkxS+qqqq69DfgnL9+EngynmWJSBy4Oy0e+dUBd2iJTlDpDo63bWv9OUe9PrL9qOc4TU0tfFxdy4q11azasJWtNXWEaCCcfZhxg7MoH5TFmHAGI/KczMP1cPgAHDrmcbge9m+Lvq6P/rofvPnISWTnwT2fRUIhxQQZAJuBknavi6PbRCRNmBmZrW03CVBSlMdF408DoG5/I++u38nSdXX8Zm0d//TBfgDy+mRy9qgw555exNSziigf3p+szBPcHnWH5kORMNi4FJ79S/j0FaicnZBzSKQgA+A94EwzG0Xki/864C8DrEdEerGifn35auUwvlo5DICafY38aX0d76yrY+naOn7/aQ0A+X2z2gLh3DOKKBvWn8yMdgFlBll9I4/RX4X+I+CjRQqAU+HuTWb210TW480EnnD31UHVIyLpZVB+Xy4dN5xLxw0HYMfeBt5Zv5Ola+v407o6fvfJDgD652QxZVQRU08PRwJhaH8yWgMhIwMqroZ3/gXqd0IoHNTpdElKLQhTVVXlmg1URHrCtj0NvLMueoWwro4v6uoBKMjN5pxRkTCYenoRZ7WsI+Px8+DSBVA1L+CqO2Zm77t71XHbFQAiIie3ZffBtuaid9bXsWnnQQAmlRTwov8d9BsCc38dcJUd6ywAkr4XkIhIMhg+IJerJxVz9aRiAKp31fPj1/7Myys2c/gr15C95IewZzMUjAi40thpLiARkS4oLgwxY/RA3GFLySWAw+oXgy7rlCgARES6qDQcAmBdyxAYPgk+eiHgik6NAkBEpItKogGwaWc9VM6BrSuh9rOAq4qdAkBEpIsG9etLTnYGG+vqofwqwCJjAlKEAkBEpIvMjNJwiI0766H/MBg1PdIMlCK9KxUAIiLd0BYAEGkG2rkWtq4ItqgYKQBERLqhJBxi08563B3KLoOM7JRpBlIAiIh0Q2k4xIFDzew8cAhyC+HMi2DVL6Cl+eQfDpgCQESkG1q7gh5pBpoN+7bCF38MsKrYKABERLqhNQA27YpMDcHoWZHFYlKgGUgBICLSDcWF7cYCQGSVsDGXwJpfQlNjgJWdnAJARKQbcvtkMii/b2QsQKvKOdCwGz5fHFxhMVAAiIh001FdQQFOPx9CRUk/NYQCQESkm44LgMxsGHtlZKnIxv3BFXYSCgARkW4qCYfYuucgh5pajmysnANNB+HT3wRX2EkoAEREuqk0HKLFI4vGtCk5BwpKkroZSAEgItJNx40FgCPrBa/9HRyoC6iyE1MAiIh0U4cBAJFmoJYmWPNyAFWdnAJARKSbBuf3pU9WxpGxAK2GVMCgMUk7KEwBICLSTRkZRklh7vFXAGaRqSE2/ifs3hRMcSegABARiYPjuoK2qrgm8msSrhesABARiYPScIiNddFpodsLnw4jqpKyN5ACQEQkDkrCIfY1NrHn4OHjf1g5B7Z9BDWf9nxhJ6AAEBGJg057AkFkvWDLSLqbwQoAEZE4KC06QQDkD4FRM5JuvWAFgIhIHJQUniAAINIMtGs9bF7eg1WdmAJARCQO8vpmMbBfn+PHArQquwwy+ybVzWAFgIhInJR01hUUIKcAzvxKpDtokqwXrAAQEYmTTscCtKqcA/u3w4a3eq6oE1AAiIjESWk4xJbdDRxubun4DaP/K/TJT5pmIAWAiEiclIRDNLc4W3c3dPyG7FwouxTW/EdSrBesABARiZMTjgVoVTkbGvfAZ6/3UFWdUwCIiMRJTAEw6nwIDUyKZiAFgIhInAzpn0OfzIwTB0BmVmRk8J9fhYa9PVdcBxQAIiJxkplhFBfmdj4WoFXlHGhqCHy94EACwMx+ZGafmNmHZvaSmQ0Iog4RkXg74ViAtjdNgQGlgTcDBXUF8DpQ4e7jgD8D3wqoDhGRuDrpWACILBRTMRvWvgn7a3qmsA4EEgDu/pq7N0VfvgMUB1GHiEi8lYZD7Dl4mD31HUwL3V7lbPDmQNcLToZ7AF8HXunsh2Z2u5ktM7NlNTXBJaWISCxKoj2BNu06yVXAkHIYPDbQKaITFgBm9oaZrergcUW793wHaAKe6Ww/7r7Q3avcvWrQoEGJKldEJC5i6graqnI2bHoHdn2R4Ko6lrAAcPeZ7l7RweOXAGY2F7gUuMGPW0NNRCQ1lYRzgRgDoHW94FW/SGBFnQuqF9As4B+Ay909ht8lEZHUkJ+TTTivT2wBUDgSiqekVwAA/wzkA6+b2QozeyygOkRE4q4klrEArSrnwPZVsH1NYovqQFC9gL7k7iXuPiH6+EYQdYiIJEJMYwFalV8ZWS94Vc/fDE6GXkAiIr1KaTjE5l0HaW6J4fZmv8Fw+vmR3kA9fDtUASAiEmel4RBNLc7WPQdj+0DlHNj9BVQvS2xhx1AAiIjE2Sl1BQUYc2kg6wUrAERE4qxtMFisAZDTP7Ja2OoXobnp5O+PEwWAiEicDSvIISvDYr8CgEgz0IEa2LAkcYUdQwEgIhJnWZkZjCjMZePOGO8BAJx5EfTt36NTQygAREQSIKZZQdvLzoGyy2DNr+DwKQRHNygAREQSoCQciv0eQKvK2XBoH3z2WmKKOoYCQEQkAUrDIXYeOMS+hpNMC93eyBmQN7jHmoEUACIiCVDa1hPoFJpzMrOg4mr482+hYU+CKjtCASAikgCnPBagVcVsaG6Ej3+dgKqOpgAQEUmAUx4L0Kq4Cgac1iODwhQAIiIJUJCbTUFu9qlfAZhFxgSs/wPs35GY4qIUACIiCXLKXUFbVc4Gb4HVL8W/qHYUACIiCVLala6gAIPLYEhFwpuBFAAiIglSEg5RHeu00MeqnA3V78HO9fEvLEoBICKSIKXhEIeaW9i+t+HUP9wD6wUrAEREEqTLXUEBBpRCydRIM1CCFopRAIiIJEi3AgAizUA1n8D21XGs6ggFgIhIggwbkENmhnXtRjBA+VVgmQlbL1gBICKSINmZGQwfkNP1K4C8gXDGBfDRL6ClJb7FoQAQEUmoLo8FaFU5B/ZshOp341dUlAJARCSBujwWoNWYS2DK7RAaGL+iorLivkcREWlTEg5Ru/8QBxqbyOvbha/cvvlw8Y/iXxi6AhARSai2aaF3deMqIEEUACIiCdTWFbROASAikla6PRYggRQAIiIJVJCbTX5OVvduBCeIAkBEJIHMrPtdQRNEASAikmAlhQoAEZG0VFoUYtOug7R0ZVroBFIAiIgkWEk4xKGmFnbsawy6lKMoAEREEixZewIpAEREEkwBICKSpkYMyMVMASAiknb6ZGUwvCA36cYCBBoAZvb3ZuZmFv9p7kREkkhJWAHQxsxKgIuAjUHVICLSU5JxMFiQVwAPA/8AJFfHWBGRBCgNh9ixr5GDh5qDLqVNTAFgZnlmlhF9PtrMLjez7K4e1MyuADa7+8oY3nu7mS0zs2U1NTVdPaSISKBKoj2BqpNoWuhYrwCWADlmNgJ4DbgJ+PcTfcDM3jCzVR08rgC+DXw3lgO7+0J3r3L3qkGDBsVYrohIcknGrqCxLk9j7l5vZrcAP3H3B8xsxYk+4O4zO9yRWSUwClhpZgDFwHIzm+Lu206hdhGRlJHSAWBm5wI3ALdEt2V25YDu/hEwuN2ONwBV7l7blf2JiKSCcF4f8vpkJlUAxNoE9LfAt4CX3H21mZ0OvJm4skREehczo6S7C8THWUxXAO7+B+APANGbwbXu/jfxKMDdR8ZjPyIiya40HGJD3YGgy2gTay+gn5lZfzPLA1YBa8zsnsSWJiLSu7SOBXBPjt7vsTYBjXX3vcCVwCtEbuLelLCqRER6odKiEA2HW6jZnxzTQscaANnRfv9XAr9y98NoAJeIyClpHQuQLPcBYg2A/wNsAPKAJWZ2GrA3UUWJiPRGydYVNNabwI8Aj7Tb9IWZXZCYkkREeqe2aaHrDgZdChD7TeACM3uodUoGM/sxkasBERGJUU52JkP75yTNFUCsTUBPAPuAr0Ufe4EnE1WUiEhvlUxjAWIdCXyGu1/T7vX3TzYVhIiIHK80HOLtz5Jj4oNYrwAOmtl/aX1hZtOA5GjEEhFJIaXhENv2NtBwOPhpoWO9AvgG8JSZFURf7wJuTkxJIiK9V2nbtNAH+dLgfoHWEtMVgLuvdPfxwDhgnLtPBL6c0MpERHqhZBoLcEorgrn73uiIYID/noB6RER6tWQaC9CdJSEtblWIiKSJgf36kJudHNNCdycANBWEiMgpMrOkWSD+hDeBzWwfHX/RG5CbkIpERHq5ZBkLcMIAcPf8nipERCRdlIRz+c+1tbg70aVxA9GdJiAREemC0nCI+kPN1B04FGgdCgARkR6WLD2BFAAiIj2sNEnGAigARER6WHFh9AqgTgEgIpJWcvtkMji/r5qARETSUTKMBVAAiIgEoDQJxgIoAEREAlASDrF1bwONTcFNC60AEBEJQGk4hDts3hXc0ioKABGRAJQWBT8WQAEgIhKAZBgLoAAQEQnAoH596ZuVwSY1AYmIpJeMDKMkHAp0MJgCQEQkIEGPBVAAiIgEpHUsgHsw62spAEREAlISDrGvsYnd9YcDOb4CQEQkIEFPC60AEBEJiAJARCRNlYQjS6srAERE0kyoTxYD+/UNbDCYAkBEJECl4dz0uwIws7vM7BMzW21mDwRVh4hIkIIcC5AVxEHN7ALgCmC8uzea2eAg6hARCVppOMSvVm7hcHML2Zk9+3/yoK4A7gB+6O6NAO6+I6A6REQCVRIO0eKwZXfPzwkUVACMBqab2Z/M7A9mdnZnbzSz281smZktq6mp6cESRUQSL8iuoAlrAjKzN4ChHfzoO9HjhoGpwNnA82Z2uncwHtrdFwILAaqqqoIZLy0ikiBBrguQsABw95md/czM7gBejH7hv2tmLcBAQP/FF5G0MiQ/hz6ZGYEEQFBNQC8DFwCY2WigD1AbUC0iIoHJyDCKw7mBjAUIpBcQ8ATwhJmtAg4BN3fU/CMikg6C6goaSAC4+yHgxiCOLSKSbErDIZZ/savHj6uRwCIiASspDLG3oYk9PTwttAJARCRgJQF1BVUAiIgELKixAAoAEZGABTUttAJARCRg+TnZhPP6KABERNJRSXSB+J6kABARSQJBjAVQAIiIJIHScC6bdx+kqbmlx46pABARSQKl4RDNLc7WPQ09dkwFgIhIEghiLIACQEQkCQQxFkABICKSBIYV5JKVYQoAEZF0k5lhFBfmKgBERNJRT48FUACIiCSJnh4LoAAQEUkSpeEQu+sPs7ehZ6aFVgCIiCSJ1p5APdUMpAAQEUkSJQoAEZH0VFrUs2MBFAAiIkmif042A0LZCgARkXQU6Ql0sEeOpQAQEUkiPTkWQAEgIpJESsMhqnfV09ziCT+WAkBEJImUhkMcbna27U38tNAKABGRJNI2K2hd4puBshJ+hAQ7fPgw1dXVNDT03CIK0j05OTkUFxeTnZ0ddCkiSaf9YLBzzyhK6LFSPgCqq6vJz89n5MiRmFnQ5chJuDt1dXVUV1czatSooMsRSTrDCnLI7KFpoVO+CaihoYGioiJ9+acIM6OoqEhXbCKdyMrMYMSAnpkWOuUDANCXf4rRn5fIifXUrKC9IgBERHqTnhoLoAAQEUkypeEQdQcOsb+xKaHHUQB00+7du/nJT35yyp+7+OKL2b179wnf893vfpc33nijq6V1qF+/fnHdn4jEX0k4F0j8rKAp3wuove//x2rWbNkb132OHd6f+y4r7/TnrQHwV3/1V0dtb2pqIiur89/e3/zmNyc99v333x97oSLSa7SNBdhZT9mw/gk7jq4Auunee+9l7dq1TJgwgbPPPpvp06dz+eWXM3bsWACuvPJKJk+eTHl5OQsXLmz73MiRI6mtrWXDhg2UlZVx2223UV5ezkUXXcTBg5GJoObOncuiRYva3n/fffcxadIkKisr+eSTTwCoqanhK1/5CuXl5dx6662cdtpp1NbWnrRud+eee+6hoqKCyspKnnvuOQC2bt3KjBkzmDBhAhUVFbz11ls0Nzczd+7ctvc+/PDDcf09FJGj9djCMO6eMo/Jkyf7sdasWXPctp60fv16Ly8vd3f3N99800OhkK9bt67t53V1de7uXl9f7+Xl5V5bW+vu7qeddprX1NT4+vXrPTMz0z/44AN3d58zZ44//fTT7u5+8803+wsvvND2/kceecTd3R999FG/5ZZb3N39zjvv9B/84Afu7v7KK6844DU1NZ3Wm5eX5+7uixYt8pkzZ3pTU5Nv27bNS0pKfMuWLf7ggw/6/Pnz3d29qanJ9+7d68uWLfOZM2e27WPXrl3d+S1z9+D/3ESSWUtLi1fc96r/z5c/isv+gGXewXeqrgDibMqUKUcNcHrkkUcYP348U6dOZdOmTXz22WfHfWbUqFFMmDABgMmTJ7Nhw4YO93311Vcf9563336b6667DoBZs2ZRWFgYU51vv/02119/PZmZmQwZMoTzzjuP9957j7PPPpsnn3yS733ve3z00Ufk5+dz+umns27dOu666y5effVV+vdP3CWpiES6SvdEV9BAAsDMJpjZO2a2wsyWmdmUIOpIhLy8vLbnv//973njjTdYunQpK1euZOLEiR0OgOrbt2/b88zMTJqaOr7z3/q+E72nu2bMmMGSJUsYMWIEc+fO5amnnqKwsJCVK1dy/vnn89hjj3Hrrbcm5NgickSvDQDgAeD77j4B+G70dUrKz89n3759Hf5sz549FBYWEgqF+OSTT3jnnXfifvxp06bx/PPPA/Daa6+xa9eumD43ffp0nnvuOZqbm6mpqWHJkiVMmTKFL774giFDhnDbbbdx6623snz5cmpra2lpaeGaa65h/vz5LF++PO7nISJHKw2HqN55kJYETgsdVC8gB1rbEQqALQHV0W1FRUVMmzaNiooKcnNzGTJkSNvPZs2axWOPPUZZWRlnnXUWU6dOjfvx77vvPq6//nqefvppzj33XIYOHUp+fv5JP3fVVVexdOlSxo8fj5nxwAMPMHToUH7605/yox/9iOzsbPr168dTTz3F5s2bmTdvHi0tLQD84z/+Y9zPQ0SOVhIOcai5he37GhhWkJuQY1jk/kDPMrMy4LeAEbkK+Qt3/6KT994O3A5QWlo6+Ysvjn7bxx9/TFlZWWILTmKNjY1kZmaSlZXF0qVLueOOO1ixYkXQZZ1Uuv+5iZzMkj/X8N+eeJfnbp/KOad3b1ZQM3vf3auO3Z6wKwAzewMY2sGPvgNcCPydu//CzL4G/Bsws6P9uPtCYCFAVVVVz6dVktu4cSNf+9rXaGlpoU+fPjz++ONBlyQicdB+LEB3A6AzCQsAd+/wCx3AzJ4C7o6+fAH410TV0dudeeaZfPDBB0dtq6ur48ILLzzuvYsXL6aoKLHzi4tIfAwfkEuGJXYsQFD3ALYA5wG/B74MHN83UrqsqKgoJZqBRKRzfbIyGFaQ2GmhgwqA24B/MrMsoIFoG7+IiByR6K6ggQSAu78NTA7i2CIiqaI0HGLxJzsStn+NBBYRSVKlRSFq9zdSfygxAz8VACIiSaqkbVK4gwnZvwKgh7XOx79lyxZmz57d4XvOP/98li1bdsL9LFiwgPr6I22DsawvcCraz0QqIsFo3xU0EXrVegC8ci9s+yi++xxaCV/9YXz3CQwfPrxbX7ALFizgxhtvJBSK/AWJZX0BEUktiQ4AXQF007333sujjz7a9vp73/se8+fP58ILL2ybu/+Xv/zlcZ/bsGEDFRUVABw8eJDrrruOsrIyrrrqqrb1AADuuOMOqqqqKC8v57777gMiM4xu2bKFCy64gAsuuAA4sr4AwEMPPURFRQUVFRUsWLCg7XidrTtwMosXL2bixIlUVlby9a9/ncbGxrZzHzt2LOPGjeOb3/wmAC+88AIVFRWMHz+eGTNmnNLvpYgcrTCUTb++WYkbC9DRHNHJ+kjG9QCWL1/uM2bMaHtdVlbmGzdu9D179ri7e01NjZ9xxhne0tLi7kfm42+/jsCPf/xjnzdvnru7r1y50jMzM/29995z9yPrCTQ1Nfl5553nK1eudPcj6wm0an29bNkyr6io8P379/u+fft87Nixvnz58hOuO9CR1rUIDh486MXFxf7pp5+6u/tNN93kDz/8sNfW1vro0aPbzqt1jYCKigqvrq4+altHgv5zE0kVsxYs8XlPvtutfaD1ABJj4sSJ7Nixgy1btrBy5UoKCwsZOnQo3/72txk3bhwzZ85k8+bNbN++vdN9LFmyhBtvvBGAcePGMW7cuLafPf/880yaNImJEyeyevVq1qxZc8J63n77ba666iry8vLo168fV199NW+99RYQ+7oD7X366aeMGjWK0aNHA3DzzTezZMkSCgoKyMnJ4ZZbbuHFF19sa4qaNm0ac+fO5fHHH6e5ufmk+xeREysNJ24wmAIgDubMmcOiRYt47rnnuPbaa3nmmWeoqanh/fffZ8WKFQwZMqTDdQBOZv369Tz44IMsXryYDz/8kEsuuaRL+2kV67oDscjKyuLdd99l9uzZ/PrXv2bWrFkAPPbYY8yfP59NmzYxefJk6urqunwMEYncB9i0sx5PwMSdCoA4uPbaa3n22WdZtGgRc+bMYc+ePQwePJjs7GzefPNNjp3B9FgzZszgZz/7GQCrVq3iww8/BGDv3r3k5eVRUFDA9u3beeWVV9o+09k6BNOnT+fll1+mvr6eAwcO8NJLLzF9+vQun9tZZ53Fhg0b+PzzzwF4+umnOe+889i/fz979uzh4osv5uGHH2blypUArF27lnPOOYf777+fQYMGsWnTpi4fW0QiAdDY1ELNvsa477t39QIKSHl5Ofv27WPEiBEMGzaMG264gcsuu4zKykqqqqoYM2bMCT9/xx13MG/ePMrKyigrK2Py5Mgg6fHjxzNx4kTGjBlDSUkJ06ZNa/vM7bffzqxZsxg+fDhvvvlm2/ZJkyYxd+5cpkyJLLJ26623MnHixJiaezqSk5PDk08+yZw5c2hqauLss8/mG9/4Bjt37uSKK66goaEBd+ehhx4C4J577uGzzz7D3bnwwgsZP358l44rIhEl7XoCDe6fE9d9B7IeQFdVVVX5sf3jNa98atKfm0hsNu2s53/9v4+584IvUVlc0KV99Ph6ACIi0n0l4RCP3ZSYqdMUAGnuzjvv5I9//ONR2+6++27mzZsXUEUi0lN6RQC4O2YWdBkpqf0gtp6SSs2OIr1ZyvcCysnJoa6uTl8qKcLdqaurIycnvjezROTUpfwVQHFxMdXV1dTU1ARdisQoJyeH4uLioMsQSXspHwDZ2dmMGjUq6DJERFJOyjcBiYhI1ygARETSlAJARCRNpdRIYDOrAU48sU7nBgK1cSwnSDqX5NNbzgN0LsmqO+dymrsPOnZjSgVAd5jZso6GQqcinUvy6S3nATqXZJWIc1ETkIhImlIAiIikqXQKgIVBFxBHOpfk01vOA3QuySru55I29wBERORo6XQFICIi7SgARETSVFoEgJnNMrNPzexzM7s36Hq6wsxKzOxNM1tjZqvN7O6ga+ouM8s0sw/M7NdB19IdZjbAzBaZ2Sdm9rGZnRt0TV1lZn8X/fu1ysx+bmYpM22rmT1hZjvMbFW7bWEze93MPov+WhhkjbHo5Dx+FP379aGZvWRmA+JxrF4fAGaWCTwKfBUYC1xvZmODrapLmoC/d/exwFTgzhQ9j/buBj4Ouog4+CfgVXcfA4wnRc/JzEYAfwNUuXsFkAlcF2xVp+TfgVnHbLsXWOzuZwKLo6+T3b9z/Hm8DlS4+zjgz8C34nGgXh8AwBTgc3df5+6HgGeBKwKu6ZS5+1Z3Xx59vo/Il8yIYKvqOjMrBi4B/jXoWrrDzAqAGcC/Abj7IXffHWxV3ZIF5JpZFhACtgRcT8zcfQmw85jNVwA/jT7/KXBljxbVBR2dh7u/5u5N0ZfvAHGZTz0dAmAEsKDbywIAAAOBSURBVKnd62pS+IsTwMxGAhOBPwVbSbcsAP4BaAm6kG4aBdQAT0abs/7VzPKCLqor3H0z8CCwEdgK7HH314KtqtuGuPvW6PNtwJAgi4mTrwOvxGNH6RAAvYqZ9QN+Afytu+8Nup6uMLNLgR3u/n7QtcRBFjAJ+Bd3nwgcIDWaGY4TbR+/gkioDQfyzOzGYKuKH4/0eU/pfu9m9h0izcHPxGN/6RAAm4GSdq+Lo9tSjpllE/nyf8bdXwy6nm6YBlxuZhuINMl92cz+b7AldVk1UO3urVdji4gEQiqaCax39xp3Pwy8CPxFwDV113YzGwYQ/XVHwPV0mZnNBS4FbvA4DeBKhwB4DzjTzEaZWR8iN7V+FXBNp8wiq97/G/Cxuz8UdD3d4e7fcvdidx9J5M/jd+6ekv/TdPdtwCYzOyu66UJgTYAldcdGYKqZhaJ/3y4kRW9ot/Mr4Obo85uBXwZYS5eZ2SwiTaaXu3t9vPbb6wMgeuPkr4HfEvnL/Ly7rw62qi6ZBtxE5H/LK6KPi4MuSgC4C3jGzD4EJgA/CLieLolexSwClgMfEfl+SJmpFMzs58BS4CwzqzazW4AfAl8xs8+IXOH8MMgaY9HJefwzkA+8Hv23/1hcjqWpIERE0lOvvwIQEZGOKQBERNKUAkBEJE0pAERE0pQCQEQkTSkARNoxs+Z23WxXxHP2WDMb2X6GR5GgZQVdgEiSOejuE4IuQqQn6ApAJAZmtsHMHjCzj8zsXTP7UnT7SDP7XXSe9sVmVhrdPiQ6b/vK6KN1SoVMM3s8Ouf+a2aWG9hJSdpTAIgcLfeYJqBr2/1sj7tXEhmVuSC67X8DP43O0/4M8Eh0+yPAH9x9PJG5gVpHn58JPOru5cBu4JoEn49IpzQSWKQdM9vv7v062L4B+LK7r4tOyrfN3YvMrBYY5u6Ho9u3uvtAM6sBit29sd0+RgKvRxcnwcz+B5Dt7vMTf2Yix9MVgEjsvJPnp6Kx3fNmdB9OAqQAEIndte1+XRp9/p8cWTbxBuCt6PPFwB3QtvZxQU8VKRIr/e9D5Gi5Zrai3etX3b21K2hhdMbPRuD66La7iKwGdg+RlcHmRbffDSyMzuTYTCQMtiKSRHQPQCQG0XsAVe5eG3QtIvGiJiARkTSlKwARkTSlKwARkTSlABARSVMKABGRNKUAEBFJUwoAEZE09f8B3M/cCsyhz14AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZWhPQjX66cMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "laycUNzQ6cQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}